{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalog-based forecast tutorial - UCERF3 Landers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will look at an example of a catalog-based forecast.  \n",
    "\n",
    "Our goal is to test whether the forecast number of earthquakes from a UCERF3-ETAS aftershock model is consistent with observations for the 1992 Landers sequence.\n",
    "The PyCSEP package has been designed so that the order of the steps that we take to do this is very similar to that for the gridded forecasts with a few differences. This tutorial aims to familiarise the user with some of the differences involved and further understanding of how these new CSEP tests are carried out.\n",
    "\n",
    "Full documentation of the package can be found [here](https://docs.cseptesting.org/) and any issues can be reported on the [PyCSEP Github page](https://github.com/SCECcode/pycsep). The theory behind catalog-based evaluations can be found [here](https://docs.cseptesting.org/getting_started/theory.html#catalog-based-forecast-tests) and the routines [here](https://docs.cseptesting.org/concepts/evaluations.html#catalog-based-forecast-evaluations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the core functionality can be imported from the top-level csep package. \n",
    "import csep\n",
    "\n",
    "# Or you could import directly from submodules, like csep.core or csep.utils submodules.\n",
    "from csep.core import regions, catalog_evaluations\n",
    "from csep.core import poisson_evaluations as poisson\n",
    "from csep.utils import datasets, time_utils, comcat, plots\n",
    "\n",
    "import numpy\n",
    "import cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load forecast\n",
    "\n",
    "Forecasts should define a time horizon in which they are valid. The choice is flexible for catalog-based forecasts, because the catalogs can be filtered to accommodate multiple end-times. Conceptually, these should be separate forecasts.  \n",
    "\n",
    "For catalog-based forecasts, we need to explicitly compute bin-wise rates. Before we can compute the bin-wise rates we need to define a spatial region and a set of magnitude bin edges. The magnitude bin edges # are the lower bound (inclusive) except for the last bin, which is treated as extending to infinity. We can bind these # to the forecast object.  \n",
    "\n",
    "The spatial region should also be explicitly defined, in contrast to the gridded forecast where this is extracted from the data. In this example, we use the RELM polygon included in the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up model parameters\n",
    "\n",
    "# Start and end time\n",
    "start_time = time_utils.strptime_to_utc_datetime(\"1992-06-28 11:57:34.14\")\n",
    "end_time = time_utils.strptime_to_utc_datetime(\"1992-07-28 11:57:34.14\")\n",
    "\n",
    "# Magnitude bins properties\n",
    "min_mw = 4.95\n",
    "max_mw = 8.95\n",
    "dmw = 0.1\n",
    "\n",
    "# Create space and magnitude regions. The forecast is already filtered in space and magnitude\n",
    "magnitudes = regions.magnitude_bins(min_mw, max_mw, dmw)\n",
    "region = regions.california_relm_region()\n",
    "\n",
    "# Bind region information to the forecast (this will be used for binning of the catalogs)\n",
    "\n",
    "space_magnitude_region = regions.create_space_magnitude_region(region, magnitudes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the file size of this example, we’ve already pre-filtered the catalogs to the appropriate magnitudes and spatial locations. The format of catalogs and catalog-based forecasts is similar, with two extra columns in forecasts to represent the synthetic catalog id or the event id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "lon\t        lat\t        mag \ttime_string\t                depth\t    catalog_id\tevent_id(optional)\n",
    "-124.56793\t40.419548\t5.65\t1992-07-10T19:10:07.057000\t18.083824\t0\t\n",
    "-124.56\t    40.4\t    6.69\t1992-08-30T16:44:54.183000\t21.0    \t0\t\n",
    "-124.319466\t40.21936\t5.15\t1992-08-30T21:14:55.449000\t6.1641793\t0\n",
    "...\n",
    "-116.36257\t33.96388\t5.25\t1992-09-11T14:57:55.473000\t0.25818658\t1\t\n",
    "-121.804115\t35.214355\t4.95\t1992-11-15T13:46:20.408000\t4.7234006\t1\n",
    "...\t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The forecast is loaded simply as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast = csep.load_catalog_forecast('../workshop_data/forecasts/ucerf3-landers.csv',\n",
    "                                      start_time = start_time,\n",
    "                                      end_time = end_time,\n",
    "                                      region = space_magnitude_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original forecast was computed for 1 year following the start date, so we still need to filter the forecast in time. We can do this by passing a list of filtering arguments to the forecast or updating the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.filters = [f'origin_time >= {forecast.start_epoch}', f'origin_time < {forecast.end_epoch}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `csep.core.forecasts.CatalogForecast` provides a method to compute the expected number of events in spatial cells. This requires a region with magnitude information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 catalogs in 7.664 seconds\n"
     ]
    }
   ],
   "source": [
    "# Assign filters to forecast (in this case time)\n",
    "expected_rates = forecast.get_expected_rates(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected rates can now be plotted in a similar manner to the gridded forecast plots. Again, we can specify plot arguments as we did for the gridded forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_forecast = {'title': 'Landers aftershock forecast',\n",
    "                 'grid_labels': True,\n",
    "                 'basemap': 'ESRI_imagery',\n",
    "                 'cmap': 'rainbow',\n",
    "                 'alpha_exp': 0.5,\n",
    "                 'projection': cartopy.crs.Mercator(),\n",
    "                 'clim':[-3.5, 0]}\n",
    "\n",
    "ax = expected_rates.plot(plot_args = args_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter evaluation catalog\n",
    "\n",
    "In this example we use the `csep.query_comcat` function to obtain a catalog directly from [ComCat](https://earthquake.usgs.gov/data/comcat/). We need to filter the ComCat catalog to be consistent with the forecast. This can be done either through the ComCat API or using catalog filtering strings (see the gridded forecast example). Here we’ll use the Comcat API to make the data access quicker for this example. We still need to filter the observed catalog in space though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Comcat catalog and filter to region.\n",
    "comcat_catalog = csep.query_comcat(start_time, end_time, min_magnitude=forecast.min_magnitude)\n",
    "\n",
    "# Filter observed catalog using the same region as the forecast\n",
    "comcat_catalog = comcat_catalog.filter_spatial(forecast.region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the catalog\n",
    "The catalog can be plotted easily using the plot function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comcat_catalog.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's try changing some plot arguments by looking at the docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Composite plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a multiple plot, that includes the forecast expected rates and the observed catalog.\n",
    "* We must first create a forecast plot, which returns a matplotlib.pyplot.ax object.\n",
    "* This ax object should be passed to catalog.plot() as argument. \n",
    "* The plot order could be reversed, depending which layer is wanted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_catalog = {'basemap': 'ESRI_terrain',\n",
    "                'markercolor': 'black',\n",
    "                'markersize': 4}\n",
    "ax_1 = expected_rates.plot(plot_args=args_forecast)\n",
    "ax_2 = comcat_catalog.plot(ax=ax_1, plot_args=args_catalog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform a test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a forecast and evaluation catalog, tests can be easily applied in a similar way as with gridded forecasts. For example, we can perform the Number test on the catalog based forecast using the observed catalog we obtained from Comcat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_test_result = catalog_evaluations.number_test(forecast, comcat_catalog)\n",
    "ax = number_test_result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly perform a spatial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_test_result = catalog_evaluations.spatial_test(forecast, comcat_catalog)\n",
    "ax = spatial_test_result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for the reader\n",
    "\n",
    "How should the above figure be interpreted? What does this test result tell you about the forecast?\n",
    "How well does this model perform spatially?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
